# Recursos Python para AplicaÃ§Ã£o Enterprise N8N Backup/Restore

## IntroduÃ§Ã£o

Este documento detalha os recursos e bibliotecas Python 3 necessÃ¡rios para implementar uma aplicaÃ§Ã£o **segura, robusta e enterprise-grade** para backup/restore de N8N integrada ao Docker. O foco estÃ¡ em garantir operaÃ§Ãµes atÃ´micas, verificaÃ§Ãµes de integridade e recuperaÃ§Ã£o automÃ¡tica em cenÃ¡rios de falha.

---

## Ãndice

1. [Bibliotecas Core do Python](#bibliotecas-core-do-python)
2. [IntegraÃ§Ã£o Docker](#integraÃ§Ã£o-docker)
3. [Gerenciamento de Estado de Container](#gerenciamento-de-estado-de-container)
4. [VerificaÃ§Ã£o de Integridade e Healthchecks](#verificaÃ§Ã£o-de-integridade-e-healthchecks)
5. [SeguranÃ§a e GestÃ£o de Credenciais](#seguranÃ§a-e-gestÃ£o-de-credenciais)
6. [Logging e Auditoria](#logging-e-auditoria)
7. [ManipulaÃ§Ã£o de Dados e ValidaÃ§Ã£o](#manipulaÃ§Ã£o-de-dados-e-validaÃ§Ã£o)
8. [IntegraÃ§Ã£o com RepositÃ³rios de Backup](#integraÃ§Ã£o-com-repositÃ³rios-de-backup)
9. [Tratamento de Erros e Recovery](#tratamento-de-erros-e-recovery)
10. [Testes e Qualidade](#testes-e-qualidade)
11. [ConfiguraÃ§Ã£o e Environment](#configuraÃ§Ã£o-e-environment)
12. [CenÃ¡rios CrÃ­ticos - AnÃ¡lise Detalhada](#cenÃ¡rios-crÃ­ticos---anÃ¡lise-detalhada)

---

## Bibliotecas Core do Python

### 1. **docker** (docker-py / Docker SDK for Python)

**InstalaÃ§Ã£o**: `pip install docker`

**PropÃ³sito**: Interface Python oficial para Docker Engine API, permitindo controle programÃ¡tico completo de containers, imagens, volumes e redes.

**Capacidades CrÃ­ticas**:
- ComunicaÃ§Ã£o com Docker daemon via socket Unix (`/var/run/docker.sock`) ou TCP
- OperaÃ§Ãµes sÃ­ncronas e assÃ­ncronas em containers
- Stream de logs em tempo real
- Gerenciamento de eventos Docker
- InspeÃ§Ã£o detalhada de estado de containers

**Por que Ã© essencial**:
- **Controle fino**: Diferente de `subprocess` chamando `docker` CLI, a API nativa oferece controle granular e retornos estruturados
- **Atomicidade**: OperaÃ§Ãµes podem ser encadeadas com tratamento de erro preciso
- **Performance**: ComunicaÃ§Ã£o direta com daemon, sem overhead de spawnar processos
- **Dados estruturados**: Respostas em formato Python (dicts, objetos), nÃ£o parsing de texto

**Alternativas consideradas e descartadas**:
- `subprocess + docker CLI`: Parsing de texto frÃ¡gil, difÃ­cil tratamento de erros
- `sh` library: AbstraÃ§Ã£o desnecessÃ¡ria sobre subprocess, mesmos problemas

---

### 2. **requests** ou **httpx**

**InstalaÃ§Ã£o**: `pip install requests` ou `pip install httpx`

**PropÃ³sito**: Cliente HTTP robusto para verificar healthchecks de aplicaÃ§Ãµes, APIs REST e endpoints de monitoramento.

**Capacidades CrÃ­ticas**:
- RequisiÃ§Ãµes HTTP/HTTPS com retry automÃ¡tico configurÃ¡vel
- Timeout granular (connect, read)
- SSL/TLS verification
- Session management para reutilizar conexÃµes
- Tratamento de redirects e cookies

**Por que Ã© essencial para N8N**:
- **Verificar N8N operacional**: ApÃ³s iniciar container, consultar `http://localhost:5678/healthz` ou `/rest/workflows`
- **Healthcheck inteligente**: NÃ£o basta container "running", precisa verificar se N8N responde
- **Timeout configurÃ¡vel**: Evitar bloqueio infinito se N8N travou
- **Retry logic**: Tentativas com backoff exponencial durante startup

**httpx vs requests**:
- **requests**: Biblioteca madura, amplamente usada, sÃ­ncrona
- **httpx**: Suporta async/await, HTTP/2, API moderna, melhor para aplicaÃ§Ãµes assÃ­ncronas
- **RecomendaÃ§Ã£o**: `requests` para simplicidade inicial, `httpx` se precisar operaÃ§Ãµes assÃ­ncronas

---

### 3. **pathlib** (stdlib)

**InstalaÃ§Ã£o**: Nativa (Python 3.4+)

**PropÃ³sito**: ManipulaÃ§Ã£o orientada a objetos de caminhos de sistema de arquivos, substituindo `os.path`.

**Capacidades CrÃ­ticas**:
- OperaÃ§Ãµes de caminho cross-platform (Linux, Windows, macOS)
- VerificaÃ§Ã£o de existÃªncia, permissÃµes, tipo (arquivo/diretÃ³rio)
- CriaÃ§Ã£o de diretÃ³rios com `mkdir(parents=True, exist_ok=True)`
- IteraÃ§Ã£o de arquivos com `glob()` e `rglob()`
- Leitura/escrita de arquivos com mÃ©todos integrados

**Por que Ã© essencial**:
- **SeguranÃ§a**: `Path.resolve()` normaliza caminhos, evita directory traversal attacks
- **Legibilidade**: `backup_dir / "credentials" / "file.json"` vs concatenaÃ§Ã£o de strings
- **Type safety**: Objetos `Path` sÃ£o tipados, IDEs detectam erros
- **Cross-platform**: Funciona em Linux (produÃ§Ã£o) e Windows (dev) sem mudanÃ§as

**Exemplo de uso crÃ­tico**:
- Verificar `/tmp/bkpfile` existe antes de montar volume
- Validar arquivos JSON baixados do repositÃ³rio
- Criar estrutura de diretÃ³rios com timestamp `YYYYMMDD-HHMMSS-{server}-n8n-*`

---

### 4. **subprocess** (stdlib)

**InstalaÃ§Ã£o**: Nativa

**PropÃ³sito**: Executar comandos externos quando necessÃ¡rio (exemplo: `rsync`, `tar`, `rclone`).

**Capacidades CrÃ­ticas**:
- Executar processos com controle de stdin/stdout/stderr
- Timeout para evitar processos travados
- Captura de exit codes e tratamento de erros
- Streams de output em tempo real
- Environment variables isoladas por processo

**Por que ainda Ã© necessÃ¡rio**:
- **Ferramentas externas**: Algumas operaÃ§Ãµes sÃ£o melhores com tools nativos (rsync, tar)
- **Compatibilidade**: Scripts legados podem precisar ser chamados
- **Performance**: `rsync` otimizado em C Ã© mais rÃ¡pido que implementaÃ§Ã£o Python pura

**Cuidados de seguranÃ§a**:
- **NUNCA** usar `shell=True` com input do usuÃ¡rio (shell injection)
- Sempre usar lista de argumentos: `["rsync", "-avz", source, dest]`
- Validar paths antes de passar para comandos externos
- Capturar e logar stderr para auditoria

---

## IntegraÃ§Ã£o Docker

### 5. **docker.models.containers.Container**

**PropÃ³sito**: Objeto Python representando um container Docker com mÃ©todos para controle de ciclo de vida.

**MÃ©todos CrÃ­ticos**:

#### **`container.stop(timeout=10)`**
- **Comportamento**: Envia SIGTERM para processo principal, aguarda `timeout` segundos, entÃ£o envia SIGKILL se necessÃ¡rio
- **Retorno**: None (sÃ­ncrono, bloqueia atÃ© parada)
- **ExceÃ§Ãµes**: `docker.errors.APIError` se falha na comunicaÃ§Ã£o com daemon
- **Uso crÃ­tico**: Parar N8N gracefully antes de restore, permitindo finalizaÃ§Ã£o de workflows em execuÃ§Ã£o

#### **`container.start()`**
- **Comportamento**: Inicia container previamente parado (nÃ£o cria novo)
- **Retorno**: None (sÃ­ncrono)
- **ExceÃ§Ãµes**: `docker.errors.APIError` se container nÃ£o existe ou jÃ¡ estÃ¡ running
- **Uso crÃ­tico**: Reiniciar N8N apÃ³s backup/restore completados

#### **`container.restart(timeout=10)`**
- **Comportamento**: Equivalente a `stop()` + `start()`, mas atÃ´mico
- **Vantagem**: OperaÃ§Ã£o Ãºnica, menor janela de inconsistÃªncia
- **Uso crÃ­tico**: Aplicar mudanÃ§as de configuraÃ§Ã£o que requerem reinÃ­cio

#### **`container.wait(timeout=None, condition='not-running')`**
- **Comportamento**: Bloqueia atÃ© container atingir condiÃ§Ã£o especificada
- **Conditions**: `'not-running'`, `'next-exit'`, `'removed'`
- **Retorno**: Dict com `StatusCode` e `Error` (se houver)
- **Uso crÃ­tico**: Garantir parada completa antes de executar backup

#### **`container.reload()`**
- **Comportamento**: Atualiza atributos do objeto com estado atual do container no daemon
- **Por que necessÃ¡rio**: Estado em memÃ³ria pode ficar desatualizado se outro processo modificar container
- **Uso crÃ­tico**: Sempre chamar antes de verificar `container.status` apÃ³s operaÃ§Ãµes

#### **`container.logs(timestamps=True, tail='all')`**
- **Comportamento**: Retorna logs do container
- **Retorno**: Generator (stream) ou string completa
- **ParÃ¢metros Ãºteis**: `since`, `until`, `follow` (stream contÃ­nuo)
- **Uso crÃ­tico**: Capturar logs de erro durante falhas de backup/restore

---

### 6. **docker.client.DockerClient**

**PropÃ³sito**: Cliente principal para interagir com Docker daemon.

**InicializaÃ§Ã£o**:
- `docker.from_env()`: Usa variÃ¡veis de ambiente (DOCKER_HOST, DOCKER_TLS_VERIFY, etc.)
- `docker.DockerClient(base_url='unix://var/run/docker.sock')`: ConfiguraÃ§Ã£o explÃ­cita

**MÃ©todos CrÃ­ticos**:

#### **`client.containers.get(container_id_or_name)`**
- **Comportamento**: Retorna objeto `Container` pelo ID ou nome
- **ExceÃ§Ãµes**: `docker.errors.NotFound` se nÃ£o existe
- **Uso crÃ­tico**: Buscar container N8N no inÃ­cio da operaÃ§Ã£o

#### **`client.containers.list(filters={'name': 'n8n'})`**
- **Comportamento**: Lista containers com filtros
- **Filters Ãºteis**: `{'status': 'running'}`, `{'label': 'app=n8n'}`
- **Uso crÃ­tico**: Descobrir containers N8N dinamicamente se nome pode variar

#### **`client.containers.run(image, command, volumes, detach=True, remove=True)`**
- **Comportamento**: Cria e inicia novo container (usado para `docker run --rm`)
- **ParÃ¢metros crÃ­ticos**:
  - `volumes`: Dict mapeando host:container paths
  - `volumes_from`: Lista de container IDs para `--volumes-from`
  - `remove=True`: Equivalente a `--rm`
  - `detach=True`: Retorna imediatamente, nÃ£o espera tÃ©rmino
- **Uso crÃ­tico**: Executar comandos `n8n export/import` em container temporÃ¡rio

#### **`client.api.inspect_container(container_id)`**
- **Comportamento**: Retorna JSON completo com TODOS os detalhes do container
- **InformaÃ§Ãµes incluÃ­das**: Config, State, NetworkSettings, Mounts, HostConfig
- **Uso crÃ­tico**: Verificar volumes montados, environment variables, health status detalhado

---

### 7. **docker.errors** (MÃ³dulo de ExceÃ§Ãµes)

**ExceÃ§Ãµes CrÃ­ticas**:

#### **`docker.errors.NotFound`**
- **Quando ocorre**: Container, imagem ou volume nÃ£o existe
- **Tratamento**: Verificar prÃ©-requisitos, criar recursos faltantes, ou abortar com mensagem clara

#### **`docker.errors.APIError`**
- **Quando ocorre**: Erro na comunicaÃ§Ã£o com Docker daemon ou operaÃ§Ã£o rejeitada
- **Atributos Ãºteis**: `response.status_code`, `explanation`
- **Tratamento**: Logar detalhes, verificar permissÃµes do daemon, validar estado do sistema

#### **`docker.errors.ContainerError`**
- **Quando ocorre**: Container encerrou com exit code diferente de 0
- **Atributos Ãºteis**: `exit_status`, `stderr`, `image`, `command`
- **Tratamento**: Extrair stderr, logar comando que falhou, possÃ­vel retry se transiente

#### **`docker.errors.ImageNotFound`**
- **Quando ocorre**: Tentar rodar container com imagem nÃ£o baixada
- **Tratamento**: Pull automÃ¡tico da imagem ou abortar com instruÃ§Ãµes para pull manual

**EstratÃ©gia de tratamento**:
- Sempre capturar exceÃ§Ãµes especÃ­ficas antes de genÃ©ricas
- Logar stack trace completo para debugging
- Retornar cÃ³digos de erro especÃ­ficos para diferentes falhas
- Implementar retry logic para erros transientes (timeout de rede, daemon ocupado)

---

## Gerenciamento de Estado de Container

### Estados do Docker Container

**Estados possÃ­veis** (atributo `container.status`):
- `'created'`: Container criado mas nunca iniciado
- `'running'`: Processo principal em execuÃ§Ã£o
- `'paused'`: ExecuÃ§Ã£o congelada (via `docker pause`)
- `'restarting'`: Em processo de restart automÃ¡tico
- `'removing'`: Sendo removido
- `'exited'`: Parado (processo encerrou)
- `'dead'`: Falha irrecuperÃ¡vel (OOM, erro de driver)

### VerificaÃ§Ã£o de Parada Completa

**Desafio**: `container.stop()` retorna antes do container estar completamente parado em alguns casos (processos filhos, cleanup de volumes).

**SoluÃ§Ã£o robusta**:
1. Chamar `container.stop(timeout=30)`
2. Aguardar com `container.wait(condition='not-running', timeout=60)`
3. Fazer polling de `container.status` com `reload()` atÃ© confirmar `'exited'`
4. Verificar exit code no retorno de `wait()` - se != 0, processo encerrou anormalmente

**Por que mÃºltiplas verificaÃ§Ãµes**:
- **Race condition**: Status pode estar desatualizado se nÃ£o chamar `reload()`
- **Graceful shutdown**: N8N pode ter workflows longos que atrasam shutdown
- **Processos zumbis**: Containers podem ficar em estado intermediÃ¡rio se daemon travou

### VerificaÃ§Ã£o de Integridade do Container

**Aspectos a verificar ANTES de operaÃ§Ã£o**:

#### **1. Container existe**
- MÃ©todo: `client.containers.get(name)` nÃ£o lanÃ§a `NotFound`
- Motivo: Evitar criar operaÃ§Ãµes em container inexistente

#### **2. Volumes montados estÃ£o acessÃ­veis**
- MÃ©todo: `container.attrs['Mounts']` contÃ©m volumes esperados
- Verificar: `/home/node/.n8n` (dados N8N), `/tmp/bkpfile:/backup` (backups)
- Motivo: Sem volumes, backup nÃ£o exporta/importa dados corretos

#### **3. Environment variables crÃ­ticas presentes**
- MÃ©todo: `container.attrs['Config']['Env']` contÃ©m `N8N_ENCRYPTION_KEY`
- Motivo: Sem chave, export/import falha silenciosamente ou gera arquivos inutilizÃ¡veis

#### **4. Estado de health (se configurado)**
- MÃ©todo: `container.attrs['State']['Health']['Status']`
- Estados: `'healthy'`, `'unhealthy'`, `'starting'`, `null` (sem healthcheck)
- Motivo: Container "running" mas unhealthy indica N8N travado

#### **5. Exit code do Ãºltimo encerramento** (se reiniciado)
- MÃ©todo: `container.attrs['State']['ExitCode']`
- Valores: `0` = encerramento normal, `137` = SIGKILL (OOM?), `143` = SIGTERM
- Motivo: Exit code anormal indica problema subjacente

#### **6. OOMKilled flag**
- MÃ©todo: `container.attrs['State']['OOMKilled']`
- Motivo: Se `True`, container foi morto por falta de memÃ³ria - reiniciar sem correÃ§Ã£o causarÃ¡ nova falha

### InicializaÃ§Ã£o e VerificaÃ§Ã£o de Startup

**Processo robusto**:

#### **Fase 1: Start bÃ¡sico**
1. `container.start()`
2. Aguardar 2-3 segundos (tempo mÃ­nimo de boot do processo)

#### **Fase 2: VerificaÃ§Ã£o de estado running**
1. `container.reload()` para atualizar status
2. Verificar `container.status == 'running'`
3. Se `'exited'` ou `'dead'`, capturar logs e abortar

#### **Fase 3: Polling de logs para indicadores de startup**
1. Stream de logs com `container.logs(stream=True, follow=True)`
2. Buscar padrÃµes: "Server started", "Listening on port 5678", "Initialization complete"
3. Timeout: 60 segundos (configurÃ¡vel)
4. Se timeout ou erro nos logs, abortar

#### **Fase 4: Healthcheck de aplicaÃ§Ã£o** (mais crÃ­tico)
1. Usar `requests` para consultar endpoint N8N
2. Tentar `http://localhost:5678/healthz` (se disponÃ­vel) ou `/rest/workflows`
3. Retry com backoff exponencial: 1s, 2s, 4s, 8s, 16s (total ~31s)
4. Verificar `status_code == 200` E conteÃºdo da resposta vÃ¡lido
5. **Importante**: Container "running" â‰  N8N operacional (pode estar em crash loop)

#### **Fase 5: VerificaÃ§Ã£o funcional bÃ¡sica** (opcional mas recomendado)
1. Fazer query simples na API REST: `GET /rest/credentials?limit=1`
2. Verificar que retorna JSON vÃ¡lido (mesmo que vazio)
3. Confirma que banco de dados estÃ¡ acessÃ­vel e schema OK

**Por que tantas fases**:
- **Container running**: Processo `node` iniciou
- **Logs de startup**: N8N passou fase de inicializaÃ§Ã£o
- **Healthcheck HTTP**: Servidor web estÃ¡ respondendo
- **VerificaÃ§Ã£o funcional**: Banco de dados e core logic operacionais

---

## VerificaÃ§Ã£o de Integridade e Healthchecks

### 8. **requests com Retry Logic**

**Biblioteca adicional recomendada**: `pip install urllib3` (jÃ¡ vem com requests)

**EstratÃ©gia de Healthcheck Robusto**:

#### **Timeout Granular**
- **Connect timeout**: 5s (tempo para estabelecer conexÃ£o TCP)
- **Read timeout**: 15s (tempo para receber resposta completa)
- **Motivo**: N8N pode estar slow mas funcional (workflows pesados) - nÃ£o queremos falso negativo

#### **Retry com Backoff Exponencial**
- **Backoff**: `[1, 2, 4, 8, 16]` segundos entre tentativas
- **Total tentativas**: 5 (total ~31s esperando)
- **Status codes para retry**: `502`, `503`, `504` (server temporariamente indisponÃ­vel)
- **NÃ£o fazer retry em**: `404`, `401`, `500` (erros permanentes ou de configuraÃ§Ã£o)

#### **ValidaÃ§Ã£o de Resposta**
- NÃ£o basta `status_code == 200`
- Validar `Content-Type: application/json`
- Parsear JSON e verificar estrutura esperada
- **Exemplo**: `/rest/workflows` deve retornar `{"data": [...], "nextCursor": null}`

#### **Circuit Breaker Pattern** (avanÃ§ado)
- ApÃ³s N falhas consecutivas (ex: 3), entrar em "open state"
- Em "open", falhar imediatamente sem tentar requisiÃ§Ã£o (evitar latÃªncia)
- ApÃ³s timeout (ex: 60s), tentar uma requisiÃ§Ã£o de teste ("half-open")
- Se sucesso, voltar a "closed" (operaÃ§Ã£o normal)
- **Biblioteca recomendada**: `pybreaker` (`pip install pybreaker`)

### Endpoints N8N CrÃ­ticos para Healthcheck

#### **`/healthz`** (se disponÃ­vel em versÃ£o 2.3.0+)
- **PropÃ³sito**: Endpoint dedicado de health
- **Resposta**: `{"status": "ok"}` ou similar
- **Vantagem**: Lightweight, nÃ£o consulta banco
- **Desvantagem**: Pode nÃ£o existir em todas as versÃµes

#### **`/rest/workflows?limit=1`**
- **PropÃ³sito**: Consulta mÃ­nima ao banco de dados
- **Resposta**: JSON com array `data` (mesmo vazio)
- **Vantagem**: Confirma banco operacional
- **Desvantagem**: Requer autenticaÃ§Ã£o em alguns setups

#### **`/rest/active`**
- **PropÃ³sito**: Lista workflows ativos
- **Vantagem**: Valida que engine de execuÃ§Ã£o estÃ¡ OK
- **Desvantagem**: Mais pesado que `/healthz`

**RecomendaÃ§Ã£o de estratÃ©gia**:
1. Tentar `/healthz` primeiro (rÃ¡pido)
2. Se 404, fallback para `/rest/workflows?limit=1`
3. Se ambos falham, considerar N8N unhealthy

### VerificaÃ§Ã£o de Porta Listening

**Biblioteca**: `socket` (stdlib)

**Por que Ã© Ãºtil**:
- Confirmar que porta 5678 estÃ¡ em LISTEN antes de fazer requisiÃ§Ã£o HTTP
- Evitar timeout longo se N8N nem iniciou servidor web ainda
- Mais rÃ¡pido que requisiÃ§Ã£o HTTP completa

**LimitaÃ§Ãµes**:
- Porta aberta â‰  N8N operacional (pode ser nginx proxy, ou N8N travado apÃ³s bind)
- Deve ser combinada com healthcheck HTTP, nÃ£o substituÃ­da

---

## SeguranÃ§a e GestÃ£o de Credenciais

### 9. **python-dotenv**

**InstalaÃ§Ã£o**: `pip install python-dotenv`

**PropÃ³sito**: Carregar variÃ¡veis de ambiente de arquivo `.env` de forma segura, sem hardcode no cÃ³digo.

**Capacidades**:
- Carregar `.env` do diretÃ³rio do script ou path customizado
- NÃ£o sobrescreve variÃ¡veis jÃ¡ definidas no sistema (seguro)
- Suporta comentÃ¡rios e multiline values
- InterpolaÃ§Ã£o de variÃ¡veis dentro do `.env`

**Uso crÃ­tico para N8N**:
- Armazenar `N8N_ENCRYPTION_KEY` em `.env` (NÃƒO committado no Git)
- ConfiguraÃ§Ãµes sensÃ­veis: credenciais AWS, tokens de repositÃ³rio, etc.
- Diferentes `.env` por ambiente: `.env.production`, `.env.staging`

**Estrutura de `.env` recomendada**:
```
# N8N Configuration
N8N_ENCRYPTION_KEY=sua-chave-super-secreta-32-chars
N8N_CONTAINER_NAME=n8n-container
N8N_DOCKER_IMAGE=n8nio/n8n:latest

# Backup Configuration
BACKUP_BASE_PATH=/tmp/bkpfile
BACKUP_RETENTION_DAYS=7
SERVER_NAME=prod-server-01

# Repository Configuration (escolher um)
AWS_S3_BUCKET=empresa-backups-n8n
AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
AWS_DEFAULT_REGION=us-east-1

# Logging
LOG_LEVEL=INFO
LOG_FILE=/var/log/n8n-backup.log
```

**SeguranÃ§a do `.env`**:
- Adicionar ao `.gitignore`
- PermissÃµes: `chmod 600 .env` (somente owner pode ler/escrever)
- Nunca logar conteÃºdo de variÃ¡veis sensÃ­veis
- Usar `.env.example` com placeholders para documentaÃ§Ã£o

### 10. **hvac** (HashiCorp Vault Client)

**InstalaÃ§Ã£o**: `pip install hvac`

**PropÃ³sito**: IntegraÃ§Ã£o oficial com HashiCorp Vault para gestÃ£o enterprise de secrets.

**Por que Ã© essencial em produÃ§Ã£o**:
- `.env` Ã© OK para dev/staging, mas produÃ§Ã£o precisa de rotaÃ§Ã£o de secrets
- Vault oferece auditoria completa de acessos
- Secrets sÃ£o criptografados em rest e transit
- TTL (Time To Live) automÃ¡tico para secrets temporÃ¡rios

**Fluxo de uso**:
1. Autenticar no Vault (AppRole, Kubernetes, AWS IAM, etc.)
2. Ler secret: `client.secrets.kv.v2.read_secret_version(path='n8n/encryption-key')`
3. Secret retornado como dict Python
4. Secret pode ter metadata (versÃ£o, created_time, etc.)

**Fallback hierarchy recomendado**:
1. Tentar Vault primeiro (produÃ§Ã£o)
2. Se Vault indisponÃ­vel, fallback para `.env` (staging)
3. Se `.env` nÃ£o existe, fallback para variÃ¡vel de ambiente do sistema
4. Se nenhum funcionar, abortar com erro claro

**RotaÃ§Ã£o de secrets**:
- Vault permite versionar secrets (v1, v2, v3...)
- Script pode buscar versÃ£o especÃ­fica ou latest
- Facilita rotaÃ§Ã£o sem downtime (novo backup usa v2, old ainda pode restaurar com v1)

### 11. **cryptography**

**InstalaÃ§Ã£o**: `pip install cryptography`

**PropÃ³sito**: Biblioteca de criptografia robusta e auditada para operaÃ§Ãµes avanÃ§adas.

**Quando Ã© necessÃ¡ria**:
- N8N jÃ¡ faz criptografia com `N8N_ENCRYPTION_KEY`, entÃ£o nÃ£o precisa re-criptografar
- **MAS**: Ãºtil para criptografar logs sensÃ­veis antes de enviar para repositÃ³rio
- Validar formato de dados criptografados sem descriptografar
- Gerar checksums (SHA256) para verificar integridade de backups

**OperaÃ§Ãµes crÃ­ticas**:

#### **Hash de verificaÃ§Ã£o de integridade**
- Calcular SHA256 de arquivo de backup
- Armazenar hash em arquivo separado `.sha256`
- Antes de restore, recalcular hash e comparar
- Detecta corrupÃ§Ã£o durante transferÃªncia de rede ou storage

#### **Criptografia de logs**
- Logs podem conter trechos de credenciais em mensagens de erro
- Criptografar logs antes de upload para S3 public bucket
- Descriptografar somente quando necessÃ¡rio para debugging

#### **ValidaÃ§Ã£o de formato AES-256-CBC** (usado pelo N8N)
- Verificar que `data` field em credenciais segue formato base64(iv + ciphertext)
- NÃ£o descriptografa, mas valida estrutura
- Detecta backups corrompidos antes de tentar import

---

## Logging e Auditoria

### 12. **logging** (stdlib) com configuraÃ§Ã£o estruturada

**PropÃ³sito**: Sistema nativo de logging do Python, altamente configurÃ¡vel.

**Componentes crÃ­ticos**:

#### **Loggers hierÃ¡rquicos**
- Logger raiz: `logging.getLogger()`
- Loggers especÃ­ficos: `logging.getLogger('n8n.backup')`, `logging.getLogger('n8n.restore')`
- Hierarquia permite controle granular de nÃ­veis

#### **Handlers (destinos de log)**
- `FileHandler`: Escrever em arquivo `/var/log/n8n-backup.log`
- `RotatingFileHandler`: Rotacionar logs por tamanho (ex: max 10MB, keep 5 backups)
- `TimedRotatingFileHandler`: Rotacionar por tempo (diÃ¡rio, semanal)
- `StreamHandler`: Output para stdout/stderr (Ãºtil em containers)
- `SysLogHandler`: Enviar para syslog do sistema (integraÃ§Ã£o com logrotate)

#### **Formatters (estrutura da mensagem)**
- Simples: `'%(asctime)s - %(levelname)s - %(message)s'`
- Completo: `'%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'`
- JSON estruturado (requer biblioteca adicional):
  ```
  {
    "timestamp": "2026-01-20T14:30:00Z",
    "level": "ERROR",
    "logger": "n8n.backup",
    "message": "Falha ao exportar credenciais",
    "context": {
      "container_id": "abc123",
      "backup_path": "/tmp/bkpfile/20260120-143000"
    }
  }
  ```

#### **NÃ­veis de log**
- `DEBUG` (10): InformaÃ§Ã£o detalhada para debugging (ex: cada arquivo exportado)
- `INFO` (20): ConfirmaÃ§Ã£o que operaÃ§Ãµes funcionam como esperado (ex: backup iniciado/concluÃ­do)
- `WARNING` (30): Algo inesperado mas recuperÃ¡vel (ex: retry apÃ³s timeout)
- `ERROR` (40): Erro grave que impediu operaÃ§Ã£o (ex: container nÃ£o encontrado)
- `CRITICAL` (50): Erro catastrÃ³fico que pode derrubar sistema (ex: disco cheio)

**ConfiguraÃ§Ã£o recomendada para produÃ§Ã£o**:
- **Console (stdout)**: `INFO` (para monitoramento em tempo real via Docker logs)
- **Arquivo**: `DEBUG` (para investigaÃ§Ã£o post-mortem)
- **Syslog**: `WARNING+` (para alertas de monitoramento)

### 13. **python-json-logger** (opcional)

**InstalaÃ§Ã£o**: `pip install python-json-logger`

**PropÃ³sito**: Formatter que converte logs em JSON estruturado, ideal para ferramentas de anÃ¡lise (ELK, Splunk, CloudWatch).

**Vantagens de JSON logs**:
- **ParseÃ¡vel**: Ferramentas podem filtrar/agregar sem regex complexo
- **Campos customizados**: Adicionar `container_id`, `backup_id`, `user` automaticamente
- **IntegraÃ§Ã£o cloud**: AWS CloudWatch Insights, Azure Log Analytics processam JSON nativamente

**Desvantagens**:
- Menos legÃ­vel para humanos (usar JSON somente em produÃ§Ã£o)
- Requer ferramenta para visualizar (jq, online JSON viewers)

### Auditoria Completa

**O que logar para auditoria**:

#### **InÃ­cio de operaÃ§Ã£o**
- Timestamp, usuÃ¡rio/processo que iniciou, tipo de operaÃ§Ã£o (backup/restore)
- ParÃ¢metros: container name, backup path, flags usadas

#### **MudanÃ§as de estado**
- Container parado: timestamp, graceful vs forceful (SIGTERM vs SIGKILL)
- Container iniciado: timestamp, exit code da parada anterior

#### **OperaÃ§Ãµes de dados**
- Arquivos criados: path completo, tamanho, checksum SHA256
- Arquivos lidos: path, se validaÃ§Ã£o passou (JSON vÃ¡lido, nÃ£o-vazio)
- Uploads para repositÃ³rio: destination URL, tamanho transferido, duraÃ§Ã£o

#### **Erros e exceÃ§Ãµes**
- Stack trace completo (usar `logger.exception()` que captura automaticamente)
- Contexto: estado do sistema no momento do erro
- Tentativas de recovery e resultado

#### **Resultado final**
- Sucesso/falha, duraÃ§Ã£o total, recursos consumidos (CPU, RAM, disk I/O se disponÃ­vel)
- Para restore: nÃºmero de credenciais/workflows restaurados

**RetenÃ§Ã£o de logs**:
- Logs operacionais: 30 dias (logs diÃ¡rios)
- Logs de auditoria: 1 ano mÃ­nimo (compliance)
- Logs de erro: indefinido (ou atÃ© investigaÃ§Ã£o completa)

---

## ManipulaÃ§Ã£o de Dados e ValidaÃ§Ã£o

### 14. **json** (stdlib)

**PropÃ³sito**: Parser JSON nativo, rÃ¡pido e confiÃ¡vel.

**OperaÃ§Ãµes crÃ­ticas**:

#### **ValidaÃ§Ã£o de backup apÃ³s export**
- `json.load(file)` em cada arquivo exportado
- Se lanÃ§a `json.JSONDecodeError`, arquivo estÃ¡ corrompido
- Verificar estrutura esperada: `{'id': str, 'name': str, 'data': str}`

#### **InspeÃ§Ã£o de dados sem modificaÃ§Ã£o**
- Abrir backup, contar nÃºmero de credenciais/workflows
- Extrair metadados (created_at, updated_at) para relatÃ³rio
- Comparar IDs antes e depois de restore

**Cuidados**:
- `json.load()` carrega arquivo inteiro em memÃ³ria - OK para backups individuais (~KB), mas cuidado com consolidados grandes (>100MB)
- Usar `json.load(fp, object_hook=...)` para validaÃ§Ã£o customizada durante parsing

### 15. **pydantic** ou **marshmallow**

**InstalaÃ§Ã£o**: `pip install pydantic` ou `pip install marshmallow`

**PropÃ³sito**: ValidaÃ§Ã£o de schema de dados com type checking em runtime.

**Por que Ã© importante**:
- JSON pode estar sintaticamente vÃ¡lido mas semanticamente errado
- Exemplo: `id` pode estar presente mas ser string vazia (invÃ¡lido)
- Schema muda entre versÃµes N8N - validaÃ§Ã£o detecta incompatibilidades

**pydantic - Recomendado para Python 3.7+**:
- Usa type hints nativos do Python
- ValidaÃ§Ã£o automÃ¡tica em atribuiÃ§Ã£o
- SerializaÃ§Ã£o/deserializaÃ§Ã£o JSON integrada
- Performance excelente (usa Rust internamente em v2)

**Exemplo de schema para credencial**:
```python
from pydantic import BaseModel, Field, validator
from typing import Optional
from datetime import datetime

class N8NCredential(BaseModel):
    id: str = Field(..., min_length=1, description="UUID da credencial")
    name: str = Field(..., min_length=1, max_length=255)
    type: str = Field(..., regex=r'^[a-zA-Z0-9]+$')  # Ex: 'googleSheetsOAuth2Api'
    data: str = Field(..., min_length=1)  # Base64 encrypted data
    createdAt: datetime
    updatedAt: datetime
    
    @validator('data')
    def validate_base64(cls, v):
        import base64
        try:
            base64.b64decode(v)
        except Exception:
            raise ValueError('data deve ser base64 vÃ¡lido')
        return v
    
    @validator('createdAt', 'updatedAt')
    def validate_dates(cls, v):
        if v > datetime.now():
            raise ValueError('Data nÃ£o pode estar no futuro')
        return v
```

**Uso**:
```python
# Carregar e validar backup
with open('credential.json') as f:
    data = json.load(f)
    credential = N8NCredential(**data)  # LanÃ§a ValidationError se invÃ¡lido
```

**BenefÃ­cios em produÃ§Ã£o**:
- Detecta backups corrompidos ANTES de tentar import
- Valida dados baixados de repositÃ³rio remoto (proteÃ§Ã£o contra tampering)
- Documenta estrutura esperada (schema Ã© documentaÃ§Ã£o viva)

---

## IntegraÃ§Ã£o com RepositÃ³rios de Backup

### 16. **boto3** (AWS S3)

**InstalaÃ§Ã£o**: `pip install boto3`

**PropÃ³sito**: SDK oficial da AWS para Python, controle completo de serviÃ§os AWS.

**OperaÃ§Ãµes crÃ­ticas para backup**:

#### **Upload de arquivo com Server-Side Encryption**
```python
import boto3
s3 = boto3.client('s3')

s3.upload_file(
    Filename='/tmp/bkpfile/20260120-140000-prod-n8n-credentials.tar.gz',
    Bucket='empresa-backups',
    Key='n8n/20260120-140000-prod-n8n-credentials.tar.gz',
    ExtraArgs={
        'ServerSideEncryption': 'aws:kms',  # Criptografia gerenciada pela AWS
        'SSEKMSKeyId': 'arn:aws:kms:us-east-1:123456789012:key/abc-def',
        'StorageClass': 'STANDARD_IA',  # Infrequent Access (mais barato)
        'Metadata': {
            'backup-date': '2026-01-20',
            'server': 'prod-server-01',
            'n8n-version': '2.3.0'
        }
    }
)
```

#### **Download de backup para restore**
```python
s3.download_file(
    Bucket='empresa-backups',
    Key='n8n/20260120-140000-prod-n8n-credentials.tar.gz',
    Filename='/tmp/bkpfile/downloaded-backup.tar.gz'
)
```

#### **Listagem de backups disponÃ­veis**
```python
response = s3.list_objects_v2(
    Bucket='empresa-backups',
    Prefix='n8n/',
    MaxKeys=100
)

backups = [obj['Key'] for obj in response.get('Contents', [])]
# ['n8n/20260120-140000-...', 'n8n/20260119-140000-...', ...]
```

#### **RotaÃ§Ã£o automÃ¡tica (Lifecycle Policy)**
```python
# Definir regra de lifecycle via boto3 (fazer uma vez, fica permanente)
s3.put_bucket_lifecycle_configuration(
    Bucket='empresa-backups',
    LifecycleConfiguration={
        'Rules': [
            {
                'Id': 'DeleteOldN8NBackups',
                'Status': 'Enabled',
                'Prefix': 'n8n/',
                'Expiration': {'Days': 30},  # Deletar apÃ³s 30 dias
                'Transitions': [
                    {
                        'Days': 7,
                        'StorageClass': 'GLACIER'  # Mover para Glacier apÃ³s 7 dias (muito mais barato)
                    }
                ]
            }
        ]
    }
)
```

**Vantagens sobre aws-cli**:
- Controle programÃ¡tico: pode fazer retry, validaÃ§Ã£o, etc.
- Progress callback para uploads grandes
- Multipart upload automÃ¡tico para arquivos >5GB
- Melhor tratamento de erros (exceÃ§Ãµes tipadas)

### 17. **azure-storage-blob** (Azure Blob Storage)

**InstalaÃ§Ã£o**: `pip install azure-storage-blob`

**PropÃ³sito**: SDK oficial da Azure para blob storage.

**OperaÃ§Ãµes similares a S3**:
```python
from azure.storage.blob import BlobServiceClient, ContainerClient

blob_service = BlobServiceClient.from_connection_string(
    "DefaultEndpointsProtocol=https;AccountName=empresabackups;AccountKey=..."
)

container = blob_service.get_container_client("n8n-backups")

# Upload
with open('/tmp/bkpfile/backup.tar.gz', 'rb') as data:
    container.upload_blob(
        name='20260120-140000-prod-n8n-credentials.tar.gz',
        data=data,
        metadata={'server': 'prod-01', 'date': '2026-01-20'}
    )

# Download
with open('/tmp/downloaded.tar.gz', 'wb') as file:
    blob_client = container.get_blob_client('20260120-140000-...')
    file.write(blob_client.download_blob().readall())
```

### 18. **IntegraÃ§Ã£o com rsync via subprocess**

**Por que rsync ainda Ã© relevante**:
- TransferÃªncia incremental (sÃ³ envia diff, nÃ£o arquivo completo)
- CompressÃ£o on-the-fly
- Retomada de transferÃªncias interrompidas
- Amplamente disponÃ­vel em Linux

**ExecuÃ§Ã£o segura**:
```python
import subprocess
from pathlib import Path

def rsync_backup(source: Path, destination: str):
    """
    Args:
        source: Path local (/tmp/bkpfile/20260120-140000-*)
        destination: Remote path (backup-server:/backups/n8n/)
    """
    cmd = [
        'rsync',
        '-avz',  # archive, verbose, compress
        '--progress',
        '--timeout=300',  # Timeout se rede travar
        str(source),
        destination
    ]
    
    try:
        result = subprocess.run(
            cmd,
            check=True,  # LanÃ§a CalledProcessError se exit code != 0
            capture_output=True,
            text=True,
            timeout=600  # 10 minutos max
        )
        return result.stdout
    except subprocess.CalledProcessError as e:
        # Logar stderr para debugging
        logger.error(f"rsync falhou: {e.stderr}")
        raise
    except subprocess.TimeoutExpired:
        logger.error("rsync timeout apÃ³s 10 minutos")
        raise
```

**ValidaÃ§Ã£o SSH antes de rsync**:
- Testar conexÃ£o: `ssh -o BatchMode=yes -o ConnectTimeout=5 backup-server echo OK`
- Se falhar, nÃ£o tentar rsync (vai travar aguardando senha)

---

## Tratamento de Erros e Recovery

### 19. **tenacity** (Retry com Backoff)

**InstalaÃ§Ã£o**: `pip install tenacity`

**PropÃ³sito**: Biblioteca para retry automÃ¡tico de operaÃ§Ãµes com lÃ³gica configurÃ¡vel de backoff, stop e exceÃ§Ãµes.

**Por que Ã© crÃ­tico**:
- Erros transientes sÃ£o comuns: timeout de rede, Docker daemon temporariamente ocupado, S3 throttling
- Retry manual com loops Ã© verboso e propenso a bugs
- tenacity oferece controle declarativo e logging integrado

**Exemplo: Retry em healthcheck**:
```python
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type
)
import requests

@retry(
    stop=stop_after_attempt(5),  # MÃ¡ximo 5 tentativas
    wait=wait_exponential(multiplier=1, min=1, max=16),  # 1s, 2s, 4s, 8s, 16s
    retry=retry_if_exception_type((requests.Timeout, requests.ConnectionError))
)
def check_n8n_healthy(url: str) -> bool:
    """Verifica se N8N estÃ¡ respondendo, com retry automÃ¡tico"""
    response = requests.get(url, timeout=10)
    response.raise_for_status()  # LanÃ§a HTTPError se 4xx/5xx
    data = response.json()
    # Validar estrutura da resposta
    assert 'data' in data or 'status' in data
    return True
```

**EstratÃ©gias de retry**:

#### **Stop conditions (quando parar)**:
- `stop_after_attempt(n)`: ApÃ³s N tentativas
- `stop_after_delay(seconds)`: ApÃ³s X segundos totais
- CombinaÃ§Ã£o: `stop=(stop_after_attempt(5) | stop_after_delay(60))`

#### **Wait strategies (quanto aguardar entre tentativas)**:
- `wait_fixed(seconds)`: Intervalo fixo
- `wait_exponential()`: Backoff exponencial (1, 2, 4, 8, 16...)
- `wait_random(min, max)`: Intervalo aleatÃ³rio (evita thundering herd)
- `wait_exponential_jitter()`: Exponencial + jitter (recomendado)

#### **Retry conditions (quando tentar novamente)**:
- `retry_if_exception_type(Exception)`: Somente para exceÃ§Ãµes especÃ­ficas
- `retry_if_result(lambda x: x is None)`: Se resultado nÃ£o Ã© o esperado
- CombinaÃ§Ã£o: `retry=(retry_if_exception_type(Timeout) | retry_if_result(lambda x: x.status == 'starting'))`

**Logging de retries**:
```python
import logging

@retry(
    stop=stop_after_attempt(3),
    wait=wait_fixed(5),
    before=lambda retry_state: logger.info(f"Tentativa {retry_state.attempt_number}..."),
    after=lambda retry_state: logger.info(f"Resultado: {retry_state.outcome}")
)
def operacao_com_retry():
    pass
```

### Recovery Strategies

**CenÃ¡rio 1: Falha durante backup apÃ³s container parado**
1. Capturar exceÃ§Ã£o
2. Logar erro completo (stack trace, contexto)
3. **Recovery**: Reiniciar container IMEDIATAMENTE
4. Notificar equipe (email, Slack, PagerDuty)
5. **NÃƒO** tentar re-executar backup automaticamente (pode ter problema persistente)

**CenÃ¡rio 2: Falha durante restore (import falhou)**
1. **CRÃTICO**: Container estÃ¡ parado e estado inconsistente
2. **Recovery**: Importar backup de seguranÃ§a (feito antes do restore)
3. Se backup de seguranÃ§a tambÃ©m falha: restaurar snapshot de VM/container inteiro (disaster recovery)
4. Logar incidente como CRITICAL
5. InvestigaÃ§Ã£o manual obrigatÃ³ria antes de nova tentativa

**CenÃ¡rio 3: Upload para repositÃ³rio falhou (backup local OK)**
1. Manter backup local (NÃƒO deletar)
2. Retry upload apÃ³s intervalo (1 hora)
3. Se falha persiste: alertar equipe, backup local Ã© temporÃ¡rio
4. ApÃ³s sucesso de upload futuro, verificar se backup antigo ainda estÃ¡ local e fazer upload tardio

**CenÃ¡rio 4: Download de backup para restore falhou**
1. Verificar conectividade de rede
2. Listar backups disponÃ­veis no repositÃ³rio (garantir que existe)
3. Retry download com backoff
4. Se persiste: tentar download de backup alternativo (dia anterior)
5. **NÃƒO** prosseguir com restore sem backup vÃ¡lido

**PrincÃ­pios de recovery**:
- **Fail-safe**: Em caso de dÃºvida, deixar sistema no estado anterior (nÃ£o piorar)
- **IdempotÃªncia**: OperaÃ§Ã£o pode ser repetida sem efeito colateral
- **Auditoria**: Toda tentativa de recovery Ã© logada
- **Alertas graduais**: WARNING para retry bem-sucedido, ERROR para falha apÃ³s retries, CRITICAL para falha de recovery

---

## Testes e Qualidade

### 20. **pytest**

**InstalaÃ§Ã£o**: `pip install pytest`

**PropÃ³sito**: Framework de testes mais popular em Python, sintaxe simples e recursos avanÃ§ados.

**Tipos de teste essenciais**:

#### **Testes UnitÃ¡rios** (funÃ§Ãµes isoladas)
- Testar parsing de JSON
- ValidaÃ§Ã£o de schemas com pydantic
- FormataÃ§Ã£o de timestamps
- ConstruÃ§Ã£o de comandos Docker

#### **Testes de IntegraÃ§Ã£o** (com Docker)
- Iniciar container de teste, fazer backup, verificar arquivos gerados
- Importar backup em container limpo, verificar credenciais restauradas
- Simular falhas (kill container durante backup) e verificar recovery

#### **Fixtures** (setup/teardown de ambiente)
```python
import pytest
import docker

@pytest.fixture(scope='session')
def docker_client():
    """Cliente Docker compartilhado entre testes"""
    client = docker.from_env()
    yield client
    client.close()

@pytest.fixture
def n8n_container(docker_client):
    """Container N8N temporÃ¡rio para testes"""
    container = docker_client.containers.run(
        image='n8nio/n8n:latest',
        detach=True,
        remove=True,  # Auto-remove apÃ³s teste
        environment={'N8N_ENCRYPTION_KEY': 'test-key-32-chars-minimum-here'},
        ports={'5678/tcp': None}  # Porta aleatÃ³ria
    )
    
    # Aguardar startup
    import time
    time.sleep(10)
    
    yield container
    
    # Teardown
    container.stop()
```

#### **Mocking** (simular dependÃªncias externas)
```python
from unittest.mock import Mock, patch

@patch('boto3.client')
def test_upload_to_s3(mock_boto3):
    """Testa upload sem realmente chamar AWS"""
    mock_s3 = Mock()
    mock_boto3.return_value = mock_s3
    
    # Executar funÃ§Ã£o que usa boto3
    upload_backup_to_s3('/tmp/backup.tar.gz', 'empresa-backups')
    
    # Verificar que upload_file foi chamado
    mock_s3.upload_file.assert_called_once()
```

**Cobertura de testes** (pytest-cov):
```bash
pip install pytest-cov
pytest --cov=n8n_backup --cov-report=html
```
- Gera relatÃ³rio HTML mostrando linhas nÃ£o cobertas
- Meta: >80% de cobertura em cÃ³digo crÃ­tico

### 21. **mypy** (Type Checking EstÃ¡tico)

**InstalaÃ§Ã£o**: `pip install mypy`

**PropÃ³sito**: Analisa cÃ³digo Python e detecta erros de tipo antes da execuÃ§Ã£o.

**Por que Ã© importante**:
- Python Ã© dinamicamente tipado - erros de tipo sÃ³ aparecem em runtime
- mypy + type hints = detecÃ§Ã£o de erros em tempo de desenvolvimento
- IDEs usam type hints para autocomplete e refactoring

**Exemplo de erro detectado**:
```python
def stop_container(container_name: str) -> None:
    client = docker.from_env()
    container = client.containers.get(container_name)
    container.stop(timeout="30")  # âŒ mypy detecta: esperava int, recebeu str
```

**ConfiguraÃ§Ã£o (mypy.ini)**:
```ini
[mypy]
python_version = 3.10
warn_return_any = True
warn_unused_configs = True
disallow_untyped_defs = True  # ForÃ§ar type hints em todas as funÃ§Ãµes

# Ignorar bibliotecas sem stubs (types)
[mypy-docker.*]
ignore_missing_imports = True
```

### 22. **black** (FormataÃ§Ã£o de CÃ³digo)

**InstalaÃ§Ã£o**: `pip install black`

**PropÃ³sito**: Formatter automÃ¡tico, opinionated, sem configuraÃ§Ã£o.

**Por que Ã© importante**:
- ConsistÃªncia de cÃ³digo entre desenvolvedores
- Diffs menores em Git (sem mudanÃ§as de estilo)
- Zero debates sobre estilo (black decide)

**Uso**:
```bash
black n8n_backup/*.py
# Formata todos os arquivos Python automaticamente
```

---

## ConfiguraÃ§Ã£o e Environment

### 23. **click** ou **argparse** (CLI)

**InstalaÃ§Ã£o**: `pip install click` ou usar `argparse` (stdlib)

**PropÃ³sito**: Criar interface de linha de comando para scripts.

**click - Recomendado**:
- Sintaxe mais limpa que argparse
- ValidaÃ§Ã£o de tipos automÃ¡tica
- Help messages gerados automaticamente
- Suporte a subcomandos (como git: `git commit`, `git push`)

**Estrutura recomendada**:
```python
import click

@click.group()
def cli():
    """N8N Backup & Restore Tool"""
    pass

@cli.command()
@click.option('--container', default='n8n-container', help='Nome do container N8N')
@click.option('--output', required=True, help='DiretÃ³rio de saÃ­da')
@click.option('--upload/--no-upload', default=True, help='Upload para repositÃ³rio')
def backup(container, output, upload):
    """Executa backup de credenciais e workflows"""
    click.echo(f'Iniciando backup do container {container}...')
    # LÃ³gica de backup

@cli.command()
@click.option('--container', default='n8n-container')
@click.option('--input', required=True, help='DiretÃ³rio de backup')
@click.option('--backup-current/--no-backup-current', default=True)
def restore(container, input, backup_current):
    """Restaura credenciais e workflows"""
    click.echo(f'Restaurando backup de {input}...')
    # LÃ³gica de restore

if __name__ == '__main__':
    cli()
```

**Uso**:
```bash
python n8n_backup.py backup --container n8n-prod --output /tmp/bkpfile
python n8n_backup.py restore --input /tmp/bkpfile/20260120-140000-prod-n8n --no-backup-current
python n8n_backup.py --help  # Mostra ajuda automÃ¡tica
```

### 24. **configparser** (Arquivos INI)

**InstalaÃ§Ã£o**: Nativa (stdlib)

**PropÃ³sito**: Ler configuraÃ§Ãµes de arquivos `.ini` (alternativa a `.env` para configuraÃ§Ãµes nÃ£o-sensÃ­veis).

**Exemplo de config.ini**:
```ini
[n8n]
container_name = n8n-container
docker_image = n8nio/n8n:latest
healthcheck_url = http://localhost:5678/healthz

[backup]
base_path = /tmp/bkpfile
retention_days = 7
timestamp_format = %%Y%%m%%d-%%H%%M%%S

[repository]
type = s3  # s3, azure, rsync
s3_bucket = empresa-backups
s3_prefix = n8n/

[logging]
level = INFO
file = /var/log/n8n-backup.log
format = %%(asctime)s - %%(levelname)s - %%(message)s
```

**Leitura**:
```python
import configparser

config = configparser.ConfigParser()
config.read('config.ini')

container_name = config.get('n8n', 'container_name')
retention_days = config.getint('backup', 'retention_days')
```

**Quando usar config.ini vs .env**:
- **config.ini**: ConfiguraÃ§Ãµes nÃ£o-sensÃ­veis, pode commitar no Git
- **.env**: Secrets, credenciais, nunca commitar

---

## Gerenciamento de Ambiente Python

### 25. **uv** (Gerenciador Moderno de Ambientes e Pacotes)

**InstalaÃ§Ã£o**: 
```bash
# Linux/macOS
curl -LsSf https://astral.sh/uv/install.sh | sh

# Via pip (se jÃ¡ tem Python)
pip install uv

# Via Homebrew (macOS)
brew install uv
```

**PropÃ³sito**: Ferramenta ultra-rÃ¡pida desenvolvida em Rust pela Astral para gerenciar ambientes virtuais e pacotes Python, substituindo pip, virtualenv, poetry e pipenv com performance 10-100x superior.

**Por que Ã© essencial para projetos enterprise**:

#### **Performance Excepcional**
- **10-100x mais rÃ¡pido** que pip tradicional
- ResoluÃ§Ã£o de dependÃªncias em paralelo (multi-threaded)
- Cache global compartilhado entre projetos
- InstalaÃ§Ã£o de pacotes otimizada com HTTP/2
- CompilaÃ§Ã£o de wheels em paralelo

**Benchmark comparativo**:
```
InstalaÃ§Ã£o de 50 pacotes (django, pandas, numpy, etc.):
- pip: ~120 segundos
- poetry: ~90 segundos
- uv: ~8 segundos âš¡
```

#### **Reprodutibilidade Garantida**
- Lockfile automÃ¡tico (`uv.lock`) com hashes SHA256
- ResoluÃ§Ã£o determinÃ­stica de dependÃªncias
- CompatÃ­vel com `requirements.txt` e `pyproject.toml`
- Evita "works on my machine" em ambientes enterprise

#### **Simplicidade e Compatibilidade**
- Drop-in replacement para pip: `uv pip install` funciona igual
- NÃ£o requer mudanÃ§a de workflow existente
- CompatÃ­vel com virtualenv padrÃ£o do Python
- IntegraÃ§Ã£o nativa com Docker

---

### **Comandos Essenciais do uv**

#### **Criar ambiente virtual**
```bash
# Criar venv com Python especÃ­fico
uv venv .venv --python 3.11

# Criar com Python do sistema
uv venv .venv

# Ativar (igual virtualenv tradicional)
source .venv/bin/activate  # Linux/macOS
.venv\Scripts\activate     # Windows
```

#### **Instalar dependÃªncias**
```bash
# Instalar de requirements.txt (compatÃ­vel com pip)
uv pip install -r requirements.txt

# Instalar pacote individual
uv pip install docker requests pydantic

# Instalar com versÃ£o especÃ­fica
uv pip install "docker>=7.0.0,<8.0.0"

# Sync exato de requirements.txt (remove pacotes nÃ£o listados)
uv pip sync requirements.txt
```

#### **Gerar lockfile**
```bash
# Compilar requirements.txt com versÃµes exatas e hashes
uv pip compile requirements.in -o requirements.txt

# Atualizar dependÃªncias respeitando constraints
uv pip compile requirements.in -o requirements.txt --upgrade
```

#### **Listar pacotes instalados**
```bash
# Equivalente a pip list
uv pip list

# Equivalente a pip freeze
uv pip freeze
```

---

### **IntegraÃ§Ã£o uv com Projeto N8N Backup**

#### **Estrutura de DependÃªncias Recomendada**

**requirements.in** (dependÃªncias diretas, sem versÃµes fixas):
```txt
# Core Docker
docker>=7.0.0

# HTTP e API
requests>=2.31.0
httpx>=0.25.0

# SeguranÃ§a e Secrets
python-dotenv>=1.0.0
hvac>=2.1.0
cryptography>=41.0.0

# ValidaÃ§Ã£o e Dados
pydantic>=2.5.0

# Cloud/Storage
boto3>=1.34.0
azure-storage-blob>=12.19.0

# Retry e ResiliÃªncia
tenacity>=8.2.0

# CLI
click>=8.1.0

# Logging
python-json-logger>=2.0.0

# Dev/Test (separar em requirements-dev.in em produÃ§Ã£o)
pytest>=7.4.0
pytest-cov>=4.1.0
mypy>=1.7.0
black>=23.12.0
```

**Gerar requirements.txt com lockfile**:
```bash
# Gerar arquivo com versÃµes exatas e hashes
uv pip compile requirements.in -o requirements.txt

# ConteÃºdo de requirements.txt (exemplo):
# docker==7.0.0 \
#     --hash=sha256:abc123...
# requests==2.31.0 \
#     --hash=sha256:def456...
# ...
```

**Instalar em ambiente de produÃ§Ã£o** (reproduzÃ­vel):
```bash
uv venv .venv --python 3.11
source .venv/bin/activate
uv pip sync requirements.txt  # Instala EXATAMENTE o que estÃ¡ no lock
```

---

#### **Dockerfile Otimizado com uv**

```dockerfile
FROM python:3.11-slim

# Instalar uv (mais rÃ¡pido que pip)
COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv

# Criar usuÃ¡rio nÃ£o-root
RUN useradd -m -u 1000 n8n-backup
WORKDIR /app

# Copiar apenas requirements primeiro (cache layer)
COPY requirements.txt .

# Criar venv e instalar dependÃªncias com uv (muito mais rÃ¡pido)
RUN uv venv /app/.venv && \
    uv pip install --no-cache -r requirements.txt

# Ativar venv permanentemente
ENV PATH="/app/.venv/bin:$PATH"

# Copiar cÃ³digo da aplicaÃ§Ã£o
COPY --chown=n8n-backup:n8n-backup . .

USER n8n-backup

# Verificar instalaÃ§Ã£o
RUN python -c "import docker, requests, pydantic; print('Dependencies OK')"

CMD ["python", "src/main.py"]
```

**Vantagens desta abordagem**:
- Build time reduzido em 70-80% comparado a pip
- Layer caching eficiente (requirements muda menos que cÃ³digo)
- Imagem final menor (sem cache de pip)
- ReproduzÃ­vel (lockfile garante mesmas versÃµes)

---

#### **Scripts de AutomaÃ§Ã£o com uv**

**setup.sh** (Setup inicial do projeto):
```bash
#!/bin/bash
set -euo pipefail

echo "ğŸ”§ Configurando ambiente N8N Backup com uv..."

# Verificar se uv estÃ¡ instalado
if ! command -v uv &> /dev/null; then
    echo "âš ï¸  uv nÃ£o encontrado. Instalando..."
    curl -LsSf https://astral.sh/uv/install.sh | sh
    export PATH="$HOME/.cargo/bin:$PATH"
fi

# Criar ambiente virtual com Python 3.11
echo "ğŸ“¦ Criando ambiente virtual..."
uv venv .venv --python 3.11

# Ativar ambiente
source .venv/bin/activate

# Instalar dependÃªncias
echo "ğŸ“¥ Instalando dependÃªncias (com uv - super rÃ¡pido)..."
uv pip sync requirements.txt

# Verificar instalaÃ§Ã£o
echo "âœ… Verificando instalaÃ§Ã£o..."
python -c "import docker, requests, pydantic, boto3; print('âœ“ Todas as dependÃªncias instaladas')"

# Copiar .env.example se nÃ£o existe .env
if [ ! -f .env ]; then
    cp .env.example .env
    echo "ğŸ“ Arquivo .env criado. IMPORTANTE: Configure N8N_ENCRYPTION_KEY!"
fi

echo "âœ… Setup completo! Ative o ambiente com: source .venv/bin/activate"
```

**update-deps.sh** (Atualizar dependÃªncias):
```bash
#!/bin/bash
set -euo pipefail

echo "ğŸ”„ Atualizando dependÃªncias..."

# Recompilar com versÃµes mais recentes
uv pip compile requirements.in -o requirements.txt --upgrade

# Instalar novas versÃµes
source .venv/bin/activate
uv pip sync requirements.txt

echo "âœ… DependÃªncias atualizadas e sincronizadas"
echo "ğŸ“‹ Revise o diff de requirements.txt antes de commitar"
```

---

### **uv vs pip vs poetry vs pipenv**

| Aspecto | uv âš¡ | pip | poetry | pipenv |
|---------|------|-----|--------|--------|
| **Performance** | 10-100x mais rÃ¡pido | Base | 2-3x mais lento que pip | 2-3x mais lento que pip |
| **ResoluÃ§Ã£o de dependÃªncias** | Paralela, Rust | Linear, Python | SAT solver | Pipfile.lock |
| **Lockfile** | `uv.lock` com hashes | Manual | `poetry.lock` | `Pipfile.lock` |
| **Compatibilidade** | 100% pip | PadrÃ£o | Requer pyproject.toml | Requer Pipfile |
| **Learning curve** | MÃ­nima (comandos iguais pip) | Zero | MÃ©dia | MÃ©dia |
| **AdoÃ§Ã£o em produÃ§Ã£o** | Crescendo rÃ¡pido | Universal | Alta em Python moderno | Menor que poetry |
| **Cache compartilhado** | âœ… Sim | âŒ NÃ£o | âœ… Sim | âŒ NÃ£o |
| **Maturidade** | Novo (2023+) | Muito maduro | Maduro | Maduro |

**RecomendaÃ§Ã£o para N8N Enterprise Backup**:
- **Use uv**: Performance crÃ­tica em CI/CD e deploys frequentes
- **Mantenha compatibilidade pip**: `requirements.txt` funciona em ambos
- **TransiÃ§Ã£o gradual**: Pode usar `uv pip` como drop-in replacement sem reescrever cÃ³digo

---

### **CI/CD com uv (GitHub Actions exemplo)**

```yaml
name: Test N8N Backup

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Install uv
        uses: astral-sh/setup-uv@v1
        with:
          version: "latest"
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Create venv and install deps
        run: |
          uv venv
          source .venv/bin/activate
          uv pip sync requirements.txt
      
      - name: Run tests
        run: |
          source .venv/bin/activate
          pytest tests/ -v --cov=src
      
      - name: Type check
        run: |
          source .venv/bin/activate
          mypy src/
      
      - name: Lint
        run: |
          source .venv/bin/activate
          black --check src/
```

**Tempo de build comparado**:
- Com pip: ~3-4 minutos
- Com uv: ~30-45 segundos âš¡

---

### **Troubleshooting com uv**

#### **Conflito de dependÃªncias**
```bash
# uv mostra conflitos claramente durante compile
$ uv pip compile requirements.in

error: Because package-a==1.0.0 depends on package-b>=2.0.0
    and package-c==1.0.0 depends on package-b<2.0.0,
    we can conclude that package-a==1.0.0 and package-c==1.0.0 are incompatible.

# SoluÃ§Ã£o: Ajustar versÃµes em requirements.in
```

#### **Cache corrompido**
```bash
# Limpar cache global do uv
uv cache clean

# Reinstalar tudo do zero
rm -rf .venv
uv venv .venv
uv pip sync requirements.txt
```

#### **Migrar projeto existente de pip para uv**
```bash
# 1. Instalar uv
curl -LsSf https://astral.sh/uv/install.sh | sh

# 2. Criar requirements.in do requirements.txt atual
cp requirements.txt requirements.in

# 3. Gerar lockfile com uv
uv pip compile requirements.in -o requirements.txt

# 4. Criar novo venv com uv
uv venv .venv --python 3.11
source .venv/bin/activate

# 5. Instalar com sync
uv pip sync requirements.txt

# 6. Testar aplicaÃ§Ã£o
pytest tests/

# 7. Se tudo OK, commitar requirements.txt atualizado
```

---

### **PrÃ¡ticas Recomendadas com uv**

#### âœ… **DO's**
- Sempre usar `uv pip sync` em produÃ§Ã£o (garante ambiente exato)
- Manter `requirements.in` no Git (fonte de verdade)
- Gerar `requirements.txt` com hashes (`uv pip compile`)
- Usar `uv venv` para ambientes isolados
- Aproveitar cache global (nÃ£o usar `--no-cache` sem motivo)

#### âŒ **DON'Ts**
- NÃ£o misturar pip e uv no mesmo workflow (escolher um)
- NÃ£o editar `requirements.txt` manualmente (sempre regenerar)
- NÃ£o ignorar warnings de resoluÃ§Ã£o de dependÃªncias
- NÃ£o usar `uv pip install` diretamente em prod (usar `sync`)
- NÃ£o commitar `.venv/` no Git (adicionar ao .gitignore)

---

### **Recursos e DocumentaÃ§Ã£o uv**

- **DocumentaÃ§Ã£o Oficial**: https://docs.astral.sh/uv/
- **GitHub**: https://github.com/astral-sh/uv
- **Benchmarks**: https://astral.sh/blog/uv
- **ComparaÃ§Ã£o com pip**: https://docs.astral.sh/uv/pip/compatibility/
- **Guia de MigraÃ§Ã£o**: https://docs.astral.sh/uv/guides/integration/

---

## CenÃ¡rios CrÃ­ticos - AnÃ¡lise Detalhada

### CenÃ¡rio 1: Parar o Container

**Desafios**:
- Container pode ter workflows em execuÃ§Ã£o (podem ser interrompidos)
- N8N pode estar salvando dados no banco (risk de corrupÃ§Ã£o)
- Processos filhos podem nÃ£o encerrar gracefully
- Container pode estar em estado instÃ¡vel (travado, OOM)

**ImplementaÃ§Ã£o Robusta**:

#### **Etapa 1: VerificaÃ§Ã£o prÃ©-parada**
- Confirmar que container existe e estÃ¡ running
- Verificar se hÃ¡ workflows ativos executando (via API REST se possÃ­vel)
- Se workflows crÃ­ticos estÃ£o rodando, considerar aguardar tÃ©rmino ou avisar usuÃ¡rio

#### **Etapa 2: Graceful shutdown**
- `container.stop(timeout=30)`: Envia SIGTERM, aguarda 30s
- SIGTERM permite N8N finalizar operaÃ§Ãµes pendentes
- Se N8N nÃ£o encerra em 30s, Docker envia SIGKILL (force)

#### **Etapa 3: ConfirmaÃ§Ã£o de parada**
- `container.wait(condition='not-running', timeout=60)`
- Retorna exit code: `0` = encerramento limpo, `137` = SIGKILL (forÃ§ado), `143` = SIGTERM
- Exit code `137` indica que timeout expirou e foi forÃ§ado - **registrar como WARNING**

#### **Etapa 4: VerificaÃ§Ã£o de estado final**
- `container.reload()` + verificar `container.status == 'exited'`
- Inspecionar `container.attrs['State']['OOMKilled']` - se `True`, container foi morto por falta de memÃ³ria
- Verificar `container.attrs['State']['Error']` - pode conter mensagem de erro do Docker

#### **Tratamento de casos extremos**:

**Container jÃ¡ estava parado**:
- `container.stop()` lanÃ§a `docker.errors.APIError` com cÃ³digo 304 (Not Modified)
- Tratar como sucesso (idempotente), logar como INFO: "Container jÃ¡ estava parado"

**Container nÃ£o responde a SIGTERM**:
- Se `wait()` timeout expira, container ainda estÃ¡ running
- ForÃ§ar: `container.kill(signal='SIGKILL')`
- Logar como ERROR: "Container nÃ£o encerrou gracefully, forÃ§ado com SIGKILL"
- Investigar logs do container para identificar causa

**Container em estado 'dead'**:
- NÃ£o pode ser parado (jÃ¡ estÃ¡ "morto" mas nÃ£o removido)
- Tentar `container.remove(force=True)` para limpar
- Logar como CRITICAL: "Container em estado irrecuperÃ¡vel"

---

### CenÃ¡rio 2: Verificar Parada Completa

**Por que nÃ£o confiar apenas em `stop()` retornar**:
- `stop()` Ã© assÃ­ncrono internamente - retorna antes da parada completa em alguns casos
- Race condition: status pode estar desatualizado se outro processo modificou container
- Processos filhos (webhooks, executions) podem continuar rodando por alguns segundos

**MÃ©todo Robusto de VerificaÃ§Ã£o**:

#### **Polling com Retry**
```python
import time
from docker.errors import NotFound

def wait_for_container_stopped(container, max_wait=60):
    """
    Aguarda atÃ© container estar completamente parado.
    
    Retorna:
        True se parou, False se timeout
    """
    start_time = time.time()
    
    while time.time() - start_time < max_wait:
        try:
            container.reload()  # Atualizar estado do daemon
            
            if container.status == 'exited':
                # Verificar exit code
                exit_code = container.attrs['State']['ExitCode']
                if exit_code == 0:
                    logger.info(f"Container {container.name} parou gracefully")
                else:
                    logger.warning(f"Container {container.name} encerrou com cÃ³digo {exit_code}")
                return True
            
            elif container.status in ('dead', 'removing'):
                logger.error(f"Container {container.name} em estado anormal: {container.status}")
                return False
            
            # Ainda rodando, aguardar mais
            time.sleep(2)
            
        except NotFound:
            # Container foi removido (exemplo: restart policy auto-removeu)
            logger.warning(f"Container {container.name} nÃ£o encontrado - foi removido?")
            return False
    
    # Timeout expirou
    logger.error(f"Timeout aguardando parada de {container.name}")
    return False
```

#### **VerificaÃ§Ã£o de Processos**
- ApÃ³s `status == 'exited'`, confirmar que nenhum processo com PID do container estÃ¡ ativo
- Usar `docker.api.top(container_id)` ANTES da parada, confirmar vazio DEPOIS

#### **VerificaÃ§Ã£o de Rede**
- Se N8N estava escutando porta 5678, confirmar que porta estÃ¡ fechada
- Usar `socket.socket().connect_ex(('localhost', 5678))` - deve retornar erro (porta fechada)

---

### CenÃ¡rio 3: Verificar Integridade do Container

**Aspectos a Verificar**:

#### **1. ConfiguraÃ§Ã£o de Volumes**
```python
def verify_container_volumes(container):
    """Verifica que volumes crÃ­ticos estÃ£o montados"""
    mounts = container.attrs.get('Mounts', [])
    
    required_mounts = {
        '/home/node/.n8n': 'rw',  # Dados N8N (read-write)
        '/backup': 'rw'            # Volume de backup (read-write)
    }
    
    for mount in mounts:
        destination = mount['Destination']
        mode = mount.get('Mode', 'rw')
        
        if destination in required_mounts:
            if mode != required_mounts[destination]:
                logger.error(f"Volume {destination} tem modo {mode}, esperado {required_mounts[destination]}")
                return False
            del required_mounts[destination]
    
    if required_mounts:
        logger.error(f"Volumes faltando: {list(required_mounts.keys())}")
        return False
    
    return True
```

#### **2. Environment Variables**
```python
def verify_container_env(container):
    """Verifica que variÃ¡veis crÃ­ticas estÃ£o configuradas"""
    env_vars = container.attrs['Config']['Env']
    env_dict = dict(e.split('=', 1) for e in env_vars)
    
    required_vars = ['N8N_ENCRYPTION_KEY', 'N8N_HOST', 'N8N_PORT']
    
    for var in required_vars:
        if var not in env_dict:
            logger.error(f"VariÃ¡vel de ambiente faltando: {var}")
            return False
        
        if var == 'N8N_ENCRYPTION_KEY' and len(env_dict[var]) < 32:
            logger.error("N8N_ENCRYPTION_KEY muito curta (mÃ­nimo 32 caracteres)")
            return False
    
    return True
```

#### **3. Health Status** (se configurado)
```python
def verify_container_health(container):
    """Verifica health do container (se healthcheck configurado)"""
    health = container.attrs['State'].get('Health')
    
    if health is None:
        logger.info("Container nÃ£o tem healthcheck configurado")
        return None  # NÃ£o Ã© erro, apenas nÃ£o configurado
    
    status = health['Status']
    
    if status == 'healthy':
        return True
    elif status == 'unhealthy':
        # Capturar Ãºltimos logs de health
        failing_streak = health.get('FailingStreak', 0)
        last_log = health.get('Log', [])[-1] if health.get('Log') else {}
        logger.error(f"Container unhealthy (failing streak: {failing_streak})")
        logger.error(f"Ãšltimo healthcheck: {last_log.get('Output', 'N/A')}")
        return False
    elif status == 'starting':
        logger.info("Container ainda em startup (health: starting)")
        return None  # Aguardar mais tempo
    
    return False
```

#### **4. Integridade de Dados (arquivos crÃ­ticos)**
```python
def verify_n8n_data_integrity(container):
    """Verifica que arquivos crÃ­ticos N8N existem e estÃ£o acessÃ­veis"""
    # Executar comando dentro do container para verificar arquivos
    exit_code, output = container.exec_run('ls -la /home/node/.n8n/database.sqlite')
    
    if exit_code != 0:
        logger.error("Banco de dados N8N nÃ£o encontrado")
        return False
    
    # Verificar tamanho mÃ­nimo (banco vazio Ã© ~100KB)
    exit_code, output = container.exec_run('stat -c %s /home/node/.n8n/database.sqlite')
    
    if exit_code == 0:
        size = int(output.decode().strip())
        if size < 100000:  # 100KB
            logger.warning(f"Banco de dados muito pequeno: {size} bytes")
    
    return True
```

---

### CenÃ¡rio 4: Iniciar o Container

**Desafios**:
- Container pode nÃ£o iniciar se configuraÃ§Ã£o invÃ¡lida
- Pode iniciar mas crashar imediatamente (crash loop)
- Pode iniciar mas N8N nÃ£o fica operacional (travado)

**ImplementaÃ§Ã£o Robusta**:

#### **Etapa 1: PrÃ©-verificaÃ§Ãµes**
```python
def pre_start_checks(container):
    """VerificaÃ§Ãµes antes de iniciar container"""
    # 1. Confirmar que estÃ¡ parado
    container.reload()
    if container.status == 'running':
        logger.info("Container jÃ¡ estÃ¡ rodando")
        return True
    
    # 2. Verificar exit code da parada anterior
    exit_code = container.attrs['State'].get('ExitCode')
    if exit_code not in [0, None]:
        logger.warning(f"Container parou anormalmente (exit code {exit_code})")
    
    # 3. Verificar se OOMKilled
    if container.attrs['State'].get('OOMKilled'):
        logger.error("Container foi morto por falta de memÃ³ria na execuÃ§Ã£o anterior")
        logger.error("AÃ‡ÃƒO REQUERIDA: Aumentar memory_limit do container")
        return False
    
    # 4. Verificar espaÃ§o em disco
    # (executar no host, nÃ£o no container)
    import shutil
    stat = shutil.disk_usage('/')
    free_gb = stat.free / (1024**3)
    if free_gb < 1:  # Menos de 1GB livre
        logger.error(f"Disco cheio! Apenas {free_gb:.2f} GB livres")
        return False
    
    return True
```

#### **Etapa 2: Start com captura de erro imediato**
```python
def start_container_safely(container):
    """Inicia container e detecta falhas imediatas"""
    try:
        container.start()
        logger.info(f"Container {container.name} iniciado")
    except docker.errors.APIError as e:
        logger.error(f"Falha ao iniciar container: {e.explanation}")
        return False
    
    # Aguardar alguns segundos para detectar crash imediato
    time.sleep(5)
    
    container.reload()
    if container.status != 'running':
        logger.error(f"Container crashou imediatamente apÃ³s start (status: {container.status})")
        
        # Capturar logs de erro
        logs = container.logs(tail=50).decode('utf-8')
        logger.error(f"Logs do container:\n{logs}")
        
        return False
    
    return True
```

#### **Etapa 3: Monitorar startup via logs**
```python
def monitor_startup_logs(container, timeout=60):
    """Monitora logs de startup para detectar sucesso ou erro"""
    start_time = time.time()
    
    # PadrÃµes que indicam startup bem-sucedido
    success_patterns = [
        'Server started',
        'Listening on port',
        'Editor is now accessible',
        'Webhook waiting'
    ]
    
    # PadrÃµes que indicam erro
    error_patterns = [
        'Error:',
        'FATAL',
        'Cannot connect to database',
        'EADDRINUSE'  # Porta jÃ¡ em uso
    ]
    
    log_stream = container.logs(stream=True, follow=True)
    
    for log_line in log_stream:
        line = log_line.decode('utf-8').strip()
        logger.debug(f"[N8N] {line}")
        
        # Verificar sucesso
        for pattern in success_patterns:
            if pattern in line:
                logger.info(f"Startup detectado: {pattern}")
                return True
        
        # Verificar erro
        for pattern in error_patterns:
            if pattern in line:
                logger.error(f"Erro de startup detectado: {line}")
                return False
        
        # Timeout
        if time.time() - start_time > timeout:
            logger.error("Timeout aguardando startup (logs nÃ£o indicaram sucesso)")
            return False
    
    return False
```

---

### CenÃ¡rio 5: Verificar InicializaÃ§Ã£o Correta

**VerificaÃ§Ã£o em MÃºltiplas Camadas**:

#### **Layer 1: Container Status** (Docker)
```python
container.reload()
assert container.status == 'running'
```

#### **Layer 2: Process Running** (processo N8N vivo)
```python
# Verificar que processo node estÃ¡ rodando
exit_code, output = container.exec_run('ps aux | grep node')
assert exit_code == 0
assert 'n8n' in output.decode()
```

#### **Layer 3: Port Listening** (servidor iniciou)
```python
import socket

def check_port_open(host, port, timeout=5):
    """Verifica se porta estÃ¡ aceitando conexÃµes"""
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.settimeout(timeout)
    result = sock.connect_ex((host, port))
    sock.close()
    return result == 0  # 0 = sucesso (porta aberta)

assert check_port_open('localhost', 5678, timeout=10)
```

#### **Layer 4: HTTP Response** (web server respondendo)
```python
import requests

response = requests.get('http://localhost:5678', timeout=10)
assert response.status_code in [200, 302]  # 302 = redirect para /login
```

#### **Layer 5: Application Ready** (N8N completamente operacional)
```python
# Verificar endpoint healthcheck
response = requests.get('http://localhost:5678/healthz', timeout=10)
assert response.status_code == 200

# OU verificar API REST funcional
response = requests.get('http://localhost:5678/rest/workflows?limit=1', timeout=10)
assert response.status_code == 200
data = response.json()
assert 'data' in data
```

**EstratÃ©gia combinada**:
- Executar Layer 1 imediatamente apÃ³s `start()` (2 segundos)
- Layer 2 apÃ³s 5 segundos (tempo mÃ­nimo de boot)
- Layer 3 com retry: polling a cada 2s por atÃ© 30s
- Layer 4 com retry: apÃ³s porta abrir, tentar HTTP
- Layer 5 apenas quando Layer 4 passar

---

### CenÃ¡rio 6: Verificar N8N Operacional (E2E)

**Teste Funcional Completo**:

#### **1. Health Endpoint**
```python
def check_n8n_health():
    """Verifica endpoint de health dedicado"""
    try:
        response = requests.get(
            'http://localhost:5678/healthz',
            timeout=10
        )
        
        if response.status_code == 200:
            data = response.json()
            # Estrutura esperada: {"status": "ok"}
            if data.get('status') == 'ok':
                return True
        
        return False
    except requests.RequestException as e:
        logger.error(f"Healthcheck falhou: {e}")
        return False
```

#### **2. API REST Funcional**
```python
def check_n8n_api():
    """Verifica que API REST estÃ¡ funcional"""
    endpoints_to_test = [
        '/rest/workflows?limit=1',
        '/rest/credentials?limit=1',
        '/rest/executions?limit=1'
    ]
    
    for endpoint in endpoints_to_test:
        try:
            response = requests.get(
                f'http://localhost:5678{endpoint}',
                timeout=10
            )
            
            if response.status_code != 200:
                logger.error(f"Endpoint {endpoint} retornou {response.status_code}")
                return False
            
            data = response.json()
            if 'data' not in data:
                logger.error(f"Endpoint {endpoint} retornou estrutura invÃ¡lida")
                return False
            
        except requests.RequestException as e:
            logger.error(f"Erro ao consultar {endpoint}: {e}")
            return False
    
    return True
```

#### **3. Banco de Dados AcessÃ­vel**
```python
def check_n8n_database(container):
    """Verifica que banco estÃ¡ acessÃ­vel e schema OK"""
    # Executar query simples no SQLite
    exit_code, output = container.exec_run(
        'sqlite3 /home/node/.n8n/database.sqlite "SELECT COUNT(*) FROM credentials_entity;"'
    )
    
    if exit_code != 0:
        logger.error("Erro ao consultar banco de dados")
        return False
    
    try:
        count = int(output.decode().strip())
        logger.info(f"Banco acessÃ­vel: {count} credenciais encontradas")
        return True
    except ValueError:
        logger.error(f"Query retornou valor invÃ¡lido: {output}")
        return False
```

#### **4. Teste de Workflow Simples** (mÃ¡xima confianÃ§a)
```python
def create_and_execute_test_workflow():
    """Cria workflow de teste e executa para confirmar funcionamento completo"""
    workflow_data = {
        "name": "_HEALTHCHECK_TEST_",
        "active": False,
        "nodes": [
            {
                "id": "start",
                "type": "n8n-nodes-base.start",
                "position": [250, 300],
                "parameters": {}
            },
            {
                "id": "set",
                "type": "n8n-nodes-base.set",
                "position": [450, 300],
                "parameters": {
                    "values": {
                        "string": [
                            {
                                "name": "status",
                                "value": "ok"
                            }
                        ]
                    }
                }
            }
        ],
        "connections": {
            "start": {
                "main": [[{"node": "set", "type": "main", "index": 0}]]
            }
        }
    }
    
    try:
        # Criar workflow
        response = requests.post(
            'http://localhost:5678/rest/workflows',
            json=workflow_data,
            timeout=10
        )
        assert response.status_code == 200
        workflow_id = response.json()['id']
        
        # Executar workflow
        response = requests.post(
            f'http://localhost:5678/rest/workflows/{workflow_id}/execute',
            timeout=30
        )
        assert response.status_code == 200
        
        # Deletar workflow de teste
        requests.delete(f'http://localhost:5678/rest/workflows/{workflow_id}')
        
        logger.info("Teste funcional E2E passou: workflow executado com sucesso")
        return True
        
    except Exception as e:
        logger.error(f"Teste funcional E2E falhou: {e}")
        return False
```

**RecomendaÃ§Ã£o de uso**:
- **Desenvolvimento**: Executar somente Layers 1-4 (mais rÃ¡pido)
- **Staging**: Executar todos incluindo teste E2E
- **ProduÃ§Ã£o**: Executar 1-4 rotineiramente, E2E somente apÃ³s restore/upgrade

---

## Resumo de Bibliotecas e Ferramentas por Categoria

### Gerenciamento de Ambiente (ESSENCIAL)
0. **uv** - Gerenciador ultra-rÃ¡pido de ambientes virtuais e pacotes (10-100x mais rÃ¡pido que pip)

### Essenciais (OBRIGATÃ“RIAS)
1. **docker** - Controle de containers
2. **requests** ou **httpx** - Healthchecks HTTP
3. **pathlib** (stdlib) - ManipulaÃ§Ã£o de caminhos
4. **logging** (stdlib) - Auditoria
5. **json** (stdlib) - ValidaÃ§Ã£o de backups

### SeguranÃ§a (ALTAMENTE RECOMENDADAS)
6. **python-dotenv** - GestÃ£o de secrets
7. **hvac** - IntegraÃ§Ã£o Vault (produÃ§Ã£o)
8. **cryptography** - OperaÃ§Ãµes cripto avanÃ§adas

### RepositÃ³rios (escolher conforme infraestrutura)
9. **boto3** - AWS S3
10. **azure-storage-blob** - Azure
11. **subprocess** (stdlib) - rsync/rclone

### Qualidade (RECOMENDADAS)
12. **pydantic** - ValidaÃ§Ã£o de schemas
13. **tenacity** - Retry logic
14. **pytest** - Testes
15. **mypy** - Type checking
16. **black** - FormataÃ§Ã£o

### Usabilidade
17. **click** - Interface CLI
18. **python-json-logger** - Logs estruturados

---
Setup de ambiente com uv**:
   ```bash
   # Instalar uv
   curl -LsSf https://astral.sh/uv/install.sh | sh
   
   # Criar projeto
   mkdir n8n-backup && cd n8n-backup
   uv venv .venv --python 3.11
   source .venv/bin/activate
   ```

2. **Definir arquitetura**: Decidir entre script monolÃ­tico ou mÃ³dulos separados (backup.py, restore.py, docker_manager.py)

3. **Criar estrutura de projeto**:
   ```
   n8n-backup/
   â”œâ”€â”€ src/
   â”‚   â”œâ”€â”€ __init__.py
   â”‚   â”œâ”€â”€ backup.py
   â”‚   â”œâ”€â”€ restore.py
   â”‚   â”œâ”€â”€ docker_manager.py
   â”‚   â”œâ”€â”€ healthcheck.py
   â”‚   â””â”€â”€ repository.py
   â”œâ”€â”€ tests/
4. **Configurar dependÃªncias com uv**:
   ```bash
   # Criar requirements.in com dependÃªncias diretas
   # Gerar lockfile
   uv pip compile requirements.in -o requirements.txt
   # Instalar
6. **Adicionar testes**:
   - Testes unitÃ¡rios para cada funÃ§Ã£o
   - Testes de integraÃ§Ã£o com container real
   - Mock de APIs externas (S3, Vault)

7. **Documentar**:
   - Docstrings em todas as funÃ§Ãµes
   - README com instruÃ§Ãµes de setup (incluindo uv)
   - Runbook para operaÃ§Ãµes de emergÃªncia

8. **Integrar com CI/CD**:
   - GitHub Actions com uv (build 10x mais rÃ¡pido)
   - Lint com black + mypy
   - Build de imagem Docker otimizada com uv
   â””â”€â”€ README.md
   ```

3. **Implementar mÃ³dulos core**:
   - Docker manager (start/stop/verify)
   - Healthcheck (todas as layers)
   - Backup logic (export + upload)
   - Restore logic (download + import)

4. **Adicionar testes**:
   - Testes unitÃ¡rios para cada funÃ§Ã£o
   - Testes de integraÃ§Ã£o com container real
   - Mock de APIs externas (S3, Vault)

5. **Documentar**:
   - Docstrings em todas as funÃ§Ãµes
   - README com instruÃ§Ãµes de setup
   - Runbook para operaÃ§Ãµes de emergÃªncia

6. **Integrar com CI/CD**:
   - GitHub Actions para rodar testes
   - Lint com black + mypy
   - Build de imagem Docker (opcional)

---

Este documento serve como especificaÃ§Ã£o tÃ©cnica completa para implementaÃ§Ã£o da soluÃ§Ã£o Python. Todos os recursos mencionados sÃ£o **produÃ§Ã£o-ready** e seguem melhores prÃ¡ticas da indÃºstria.
